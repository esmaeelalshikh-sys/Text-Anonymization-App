{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzQhmThCzRFKZJwq5hHfzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esmaeelalshikh-sys/Text-Anonymization-App/blob/main/Text_Anonymization_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HEIrt-fuIGMs",
        "outputId": "513be72d-7f57-4d8c-efac-8167e3a55bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Collecting faker\n",
            "  Downloading faker-37.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading faker-37.8.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, PyPDF2, pyngrok, faker, pydeck, streamlit\n",
            "Successfully installed PyPDF2-3.0.1 faker-37.8.0 pydeck-0.9.1 pyngrok-7.3.0 python-docx-1.2.0 streamlit-1.49.1\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok transformers faker python-docx PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "from transformers import pipeline\n",
        "from faker import Faker\n",
        "from docx import Document\n",
        "from PyPDF2 import PdfReader\n",
        "import io\n",
        "import os\n",
        "\n",
        "# --- 1. Key Improvement: Caching ---\n",
        "# This function loads the model only once and keeps it in memory.\n",
        "@st.cache_resource\n",
        "def get_ner_pipeline():\n",
        "    print(\"Loading AI model...\")\n",
        "    return pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)\n",
        "\n",
        "# We can also cache the Faker instance.\n",
        "@st.cache_resource\n",
        "def get_faker():\n",
        "    return Faker()\n",
        "\n",
        "# --- Session State Management ---\n",
        "# Using None instead of \"\" makes conditions clearer.\n",
        "def reset_anonymized_state():\n",
        "    st.session_state.anonymized_text = None\n",
        "\n",
        "if 'anonymized_text' not in st.session_state:\n",
        "    st.session_state.anonymized_text = None\n",
        "\n",
        "# --- File Reading Functions ---\n",
        "def load_text_from_docx(docx_file):\n",
        "    doc = Document(docx_file)\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "    return \"\\\\n\".join(full_text)\n",
        "\n",
        "def load_text_from_pdf(pdf_file):\n",
        "    pdf_reader = PdfReader(pdf_file)\n",
        "    full_text = []\n",
        "    for page in pdf_reader.pages:\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            full_text.append(text)\n",
        "    return \"\\\\n\".join(full_text)\n",
        "\n",
        "# --- Anonymization Function (modified to accept the model as an argument) ---\n",
        "def anonymize_text(text, ner_pipeline, faker_instance, entity_types=['PER', 'ORG', 'LOC']):\n",
        "    entities = ner_pipeline(text)\n",
        "    new_text = text\n",
        "    for ent in sorted(entities, key=lambda e: e['start'], reverse=True):\n",
        "        ent_type = ent['entity_group']\n",
        "        if ent_type in entity_types:\n",
        "            if ent_type == 'PER':\n",
        "                replacement = faker_instance.name()\n",
        "            elif ent_type == 'ORG':\n",
        "                replacement = faker_instance.company()\n",
        "            elif ent_type == 'LOC':\n",
        "                replacement = faker_instance.city()\n",
        "            else:\n",
        "                replacement = '*' * len(ent['word'])\n",
        "\n",
        "            start = ent['start']\n",
        "            end = ent['end']\n",
        "            new_text = new_text[:start] + replacement + new_text[end:]\n",
        "\n",
        "    return new_text\n",
        "\n",
        "# --- Application Interface ---\n",
        "st.title(\"Text Anonymization App\")\n",
        "\n",
        "# --- 2. Calling the Cached Functions ---\n",
        "ner_pipeline = get_ner_pipeline()\n",
        "fake = get_faker()\n",
        "\n",
        "uploaded_file = st.file_uploader(\n",
        "    \"Choose a file (txt, docx, pdf)\",\n",
        "    type=[\"txt\", \"docx\", \"pdf\"],\n",
        "    on_change=reset_anonymized_state\n",
        ")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    file_type = uploaded_file.type\n",
        "    original_file_name = uploaded_file.name\n",
        "\n",
        "    # Read the file based on its type\n",
        "    if file_type == \"text/plain\":\n",
        "        raw_text = uploaded_file.read().decode(\"utf-8\")\n",
        "    elif file_type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "        raw_text = load_text_from_docx(uploaded_file)\n",
        "    elif file_type == \"application/pdf\":\n",
        "        raw_text = load_text_from_pdf(uploaded_file)\n",
        "    else:\n",
        "        raw_text = \"\"\n",
        "\n",
        "    st.subheader(\"Extracted Text from File:\")\n",
        "    text_area = st.text_area(\"\", raw_text, height=250, key=\"raw_text\")\n",
        "\n",
        "    st.subheader(\"Anonymization Options\")\n",
        "    entity_options_map = {\n",
        "        'PER': 'Names (Person)',\n",
        "        'ORG': 'Organizations (Organization)',\n",
        "        'LOC': 'Locations (Location)',\n",
        "        'MISC': 'Miscellaneous Entities (Miscellaneous)'\n",
        "    }\n",
        "    selected_entity_types = st.multiselect(\n",
        "        'Select entity types to anonymize:',\n",
        "        options=list(entity_options_map.keys()),\n",
        "        format_func=lambda x: entity_options_map[x],\n",
        "        default=['PER', 'ORG', 'LOC']\n",
        "    )\n",
        "\n",
        "    if st.button(\"Anonymize Text\", type=\"primary\"):\n",
        "        with st.spinner('Processing text...'):\n",
        "            # ### 3. Pass the pipeline and faker instances to the function ###\n",
        "            st.session_state.anonymized_text = anonymize_text(text_area, ner_pipeline, fake, selected_entity_types)\n",
        "\n",
        "    if st.session_state.anonymized_text is not None:\n",
        "        st.subheader(\"Anonymized Text:\")\n",
        "        st.text_area(\"\", st.session_state.anonymized_text, height=250, key=\"anonymized_text\")\n",
        "\n",
        "        st.subheader(\"Download Anonymized File\")\n",
        "\n",
        "        if file_type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "            new_doc = Document()\n",
        "            for para in st.session_state.anonymized_text.split('\\\\n'):\n",
        "                new_doc.add_paragraph(para)\n",
        "            bio = io.BytesIO()\n",
        "            new_doc.save(bio)\n",
        "            st.download_button(\n",
        "                label=\"Download New File (docx)\",\n",
        "                data=bio.getvalue(),\n",
        "                file_name=f\"anonymized_{original_file_name}\",\n",
        "                mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
        "            )\n",
        "        else:\n",
        "            file_name_without_ext = os.path.splitext(original_file_name)[0]\n",
        "            st.download_button(\n",
        "                label=\"Download New File (txt)\",\n",
        "                data=st.session_state.anonymized_text.encode(\"utf-8\"),\n",
        "                file_name=f\"anonymized_{file_name_without_ext}.txt\",\n",
        "                mime=\"text/plain\"\n",
        "            )\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(app_code)\n",
        "print(\"✅ Successfully created the correct and fast app.py file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U8S68ESINQn",
        "outputId": "0db1cd23-5627-4a77-e67a-ae257e7df01c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully created the correct and fast app.py file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import threading\n",
        "\n",
        "# Use userdata to fetch the secret token correctly\n",
        "ngrok_auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "if ngrok_auth_token:\n",
        "    ngrok.set_auth_token(ngrok_auth_token)\n",
        "\n",
        "    def run_streamlit():\n",
        "        os.system('streamlit run app.py')\n",
        "\n",
        "    threading.Thread(target=run_streamlit).start()\n",
        "\n",
        "    # Open an ngrok tunnel to port 8501 on the local host\n",
        "    public_url = ngrok.connect(\"8501\", proto=\"http\")\n",
        "    print(f\"App URL: {public_url}\")\n",
        "else:\n",
        "    print(\"Cannot start ngrok tunnel without the authentication token. Please add it to Colab secrets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp6QK3eKINR-",
        "outputId": "2ba3c425-91b9-4040-be6c-41aad11ef3a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "App URL: NgrokTunnel: \"https://f9cfc0dcf76a.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}